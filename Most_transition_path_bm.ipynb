{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "#import scipy.special as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle#5 as pickle\n",
    "from scipy.linalg import expm, sinm, cosm,pinv\n",
    "from numpy import linalg as LA\n",
    "from sympy import *\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import integrate\n",
    "import numpy.matlib as npm\n",
    "import matplotlib as mpl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X, weights, biases):\n",
    "    num_layers = len(weights) + 1  \n",
    "    H=X\n",
    "#    H = 2.0*(X -  X.min(0))/( X.max(0) -  X.min(0)) - 1.0\n",
    "    for l in range(0,num_layers-2):\n",
    "        W = weights[l]\n",
    "        b = biases[l]\n",
    "        H = tf.nn.tanh(tf.add(tf.matmul(H, W), b))\n",
    "    W = weights[-1]\n",
    "    b = biases[-1]\n",
    "    Y =   tf.add(tf.matmul(H, W), b)\n",
    "    return Y\n",
    "\n",
    "\n",
    "def neural_net1(X, weights, biases):\n",
    "    num_layers = len(weights) + 1  \n",
    "    H=X\n",
    "#    H = 2.0*(X -  X.min(0))/( X.max(0) -  X.min(0)) - 1.0\n",
    "    for l in range(0,num_layers-2):\n",
    "        W = weights[l]\n",
    "        b = biases[l]\n",
    "        H = tf.nn.tanh(tf.add(tf.matmul(H, W), b))\n",
    "    W = weights[-1]\n",
    "    b = biases[-1]\n",
    "    Y =  tf.exp(     tf.add(tf.matmul(H, W), b)   )\n",
    "    return Y\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]        \n",
    "    xavier_stddev = np.sqrt(2.0/(in_dim + out_dim))\n",
    "    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev,dtype=tf.float32,seed=0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_g(t, weights_g1, biases_g1, weights_g2, biases_g2):\n",
    "    g1= neural_net1(t, weights_g1, biases_g1 )\n",
    "    g2= neural_net1(t, weights_g2, biases_g2 )\n",
    "    return g1,g2\n",
    "\n",
    "# def neural_net_phi(t, weights, biases):\n",
    "#     v= neural_net(t, weights, biases)\n",
    "#     return v\n",
    "def neural_net_phi(t, weights_phi1, biases_phi1, weights_phi2, biases_phi2):\n",
    "    phi1= neural_net(t, weights_phi1, biases_phi1)   #*t*(t1-t)+(phi_R-phi_L)/(t1-t0)*t+phi_L\n",
    "    phi2= neural_net(t, weights_phi2, biases_phi2)   #*t*(t1-t)+(phi_R-phi_L)/(t1-t0)*t+phi_L\n",
    "    return phi1,phi2\n",
    "\n",
    "def potential(x,y):\n",
    "    gamma=10\n",
    "    #U= -1/2*x**2+1/4*x**4+1/2*y**2+1/2*x**2*y**2\n",
    "    U_x=x**3-x+gamma*x*y**2\n",
    "    U_y=y+x**2*y\n",
    "    return U_x,U_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "        b(x,y)=\\left(\\begin{array}{c}\n",
    "            x-x^{3}- \\beta x y^{2} \\\\-\\left(1+x^{2}\\right) y\\end{array}\n",
    "            \\right).\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "I_B(\\varphi) \\triangleq  \\inf \\left\\{\\int_{0}^{T} |g(s)|^2\\textbf{} d s \\mid g \\in \\mathcal{AC}(0,T): \\varphi(t)=x+\\int_{0}^{t} b(\\varphi(s)) d s+\\int_{0}^{t} \\sigma(\\varphi(s))g(s) d s, \\quad t \\in[0, T]\\right\\}\n",
    "\\end{equation*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \\begin{align*}\n",
    "        \\varphi_1(t)  =& x_1^{(1)}+ \\int_0^t \\big(\\varphi_1(s)-\\varphi_1^3(s)-\\varphi_1(s)\\varphi_2^2(s) \\big)ds \\\\\n",
    "        & + \\int_0^t  g_1(s)  ds, \\\\\n",
    "        \\varphi_2(t)  = &x_1^{(2)}- \\int_0^t \\big( 1+\\varphi_1^2(s) \\big) \\varphi_2(s) ds \\\\\n",
    "        &  + \\int_0^t  g_2(s)    ds.    \n",
    "    \\end{align*}\n",
    "where $g(s)=(g_1(s),g_2(s))$.\n",
    "The object function is \n",
    "\\begin{equation}\n",
    "    \\frac{1}{2}\\int_0^T |g_1^2(s)+g_2^2(s))|^{\\frac{1}{2}}ds.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def net_ode_int(x,y,t, weights_g,biases_g,alpha  ):\n",
    "#     g= neural_net_g(x,y,t, weights_g, biases_g)\n",
    "#     f1=x*(g-1) *tf.exp(-( x**2+y**2  )**(alpha/2 ) )\n",
    "#     f2=y*(g-1) *tf.exp(-( x**2+y**2  )**(alpha/2 )  )\n",
    "#     return f1,f2\n",
    "def net_ode_phi(t, weights_phi1, biases_phi1, weights_phi2, biases_phi2 ):\n",
    "    phi1=neural_net_phi(t, weights_phi1,biases_phi1  , weights_phi2, biases_phi2)[0]\n",
    "    phi2=neural_net_phi(t, weights_phi1,biases_phi1  , weights_phi2, biases_phi2)[1]\n",
    "    phi1_t = tf.gradients(phi1, t)[0]\n",
    "    phi2_t = tf.gradients(phi2, t)[0]\n",
    "    U_x=potential( phi1, phi2)\n",
    "    g1=neural_net_g(t, weights_g1, biases_g1, weights_g2, biases_g2)[0]\n",
    "    g2=neural_net_g(t, weights_g1, biases_g1, weights_g2, biases_g2)[1]\n",
    "    return phi1_t+U_x[0]-g1,phi2_t+U_x[1]-g2\n",
    "\n",
    "\n",
    "def net_opt_g(t,weights_g1,biases_g1 ,weights_g2,biases_g2 ):\n",
    "    g1=neural_net_g(t, weights_g1, biases_g1, weights_g2, biases_g2)[0]\n",
    "    g2=neural_net_g(t, weights_g1, biases_g1, weights_g2, biases_g2)[1]\n",
    "    f= 0.5*tf.sqrt(g1**2+g2**2)\n",
    "    return f\n",
    "#u_tt-v_t*(g1_v-sigma1**2/sigma2**2*g2_u)-g1*g1_u-sigma1**2/sigma2**2*g2*g2_u,#+sigma1**2/2*g1_uu+sigma1**2/2*g2_uv,\n",
    " #           v_tt-u_t*(g2_u-sigma2**2/sigma1**2*g1_v)-g2*g2_v-sigma2**2/sigma1**2*g1*g1_v#+sigma2**2/2*g2_vv+sigma2**2/2*g1_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_g = [1] + 2* [20] + [1]\n",
    "L_g = len(layers_g)\n",
    "#tt1=time.time()\n",
    "np.random.seed(0)\n",
    "\n",
    "weights_g1 = [xavier_init([layers_g[l], layers_g[l+1]]) for l in range(0, L_g-1)]    \n",
    "biases_g1 = [tf.Variable( tf.zeros((1, layers_g[l+1]),dtype=tf.float32)) for l in range(0, L_g-1)]\n",
    "\n",
    "weights_g2 = [xavier_init([layers_g[l], layers_g[l+1]]) for l in range(0, L_g-1)]    \n",
    "biases_g2 = [tf.Variable( tf.zeros((1, layers_g[l+1]),dtype=tf.float32)) for l in range(0, L_g-1)]\n",
    "\n",
    "layers_phi = [1] + 2* [20] + [1]\n",
    "L_phi = len(layers_phi)\n",
    "#tt1=time.time()\n",
    "np.random.seed(0)\n",
    "\n",
    "weights_phi1 = [xavier_init([layers_phi[l], layers_phi[l+1]]) for l in range(0, L_phi-1)]    \n",
    "biases_phi1 = [tf.Variable( tf.zeros((1, layers_phi[l+1]),dtype=tf.float32)) for l in range(0, L_phi-1)]\n",
    "\n",
    "weights_phi2 = [xavier_init([layers_phi[l], layers_phi[l+1]]) for l in range(0, L_phi-1)]    \n",
    "biases_phi2= [tf.Variable( tf.zeros((1, layers_phi[l+1]),dtype=tf.float32)) for l in range(0, L_phi-1)]\n",
    "\n",
    "reg1=0\n",
    "for i in range(L_phi-1):\n",
    "    reg1=reg1+tf.nn.l2_loss(weights_phi1[i])\n",
    " \n",
    "\n",
    "reg2=0\n",
    "for i in range(L_phi-1):\n",
    "    reg2=reg2+tf.nn.l2_loss(weights_phi2[i])\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=0\n",
    "t1=100\n",
    "Nt=10000\n",
    "dt=(t1-t0)/Nt\n",
    "vect=np.linspace(t0,t1,Nt+1)[:,None]\n",
    "vect_tf = tf.cast(vect,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L=10\n",
    "x0=-L\n",
    "x1=L\n",
    "y0=-L\n",
    "y1=L\n",
    "Nx=400\n",
    "dx=(x1-x0)/Nx\n",
    "Ny=400\n",
    "dy=(y1-y0)/Ny\n",
    "vecx=np.linspace(x0,x1,Nx+1)[:,None]\n",
    "vecy=np.linspace(y0,y1,Ny+1)[:,None]\n",
    "vecx_tf = tf.cast(vecx,dtype=tf.float32)\n",
    "vecy_tf = tf.cast(vecy,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter=0\n",
    "# xff = np.zeros((len(vect)*len(vecx) *len(vecy) ,3),dtype=np.float32)\n",
    "# for i in range(len(vect)):\n",
    "#     for j in range(len(vecx)):\n",
    "#         for k in range(len(vecy)):\n",
    "#             xff[counter,:]=[vect[i],vecx[j] ,vecy[k] ]\n",
    "#             counter=counter+1\n",
    "# tf1=xff[:,0:1]\n",
    "# xf=xff[:,1:2] \n",
    "# yf=xff[:,2:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf1_tf = tf.cast(tf1 , dtype=tf.float32)\n",
    "# xf_tf = tf.cast(xf , dtype=tf.float32)\n",
    "# yf_tf = tf.cast(yf , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(Nx/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi1_L=-1\n",
    "phi1_R=1\n",
    "phi2_L=0\n",
    "phi2_R=0\n",
    "\n",
    "\n",
    "#phi1_M=0\n",
    "#phi2_M=0\n",
    "\n",
    "phi1L_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[0][0] \n",
    "phi2L_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[1][0] \n",
    "\n",
    "\n",
    "#phi1M_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[0][int(Nx/2)] \n",
    "#phi2M_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[1][int(Nx/2)]\n",
    "\n",
    "phi1R_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[0][-1] \n",
    "phi2R_nn=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[1][-1] \n",
    "loss_b=tf.reduce_mean(tf.square(phi1L_nn-phi1_L))+ tf.reduce_mean(tf.square(phi1R_nn-phi1_R  ))+tf.reduce_mean(tf.square(phi2L_nn-phi2_L))+ tf.reduce_mean(tf.square(phi2R_nn-phi2_R  ))#+       tf.reduce_mean(tf.square(phi1M_nn-phi1_M))+ tf.reduce_mean(tf.square(phi2M_nn-phi2_M  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect_tf, weights_g1, biases_g1, weights_g2, biases_g2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_phi1=tf.reduce_mean(tf.square( net_ode_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2)[0]    ))\n",
    "\n",
    "loss_phi2=tf.reduce_mean(tf.square( net_ode_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2 )[1]    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g= dt*tf.reduce_sum( net_opt_g( vect_tf, weights_g1, biases_g1, weights_g2, biases_g2)    )\n",
    "loss_phi=loss_phi1+loss_phi2+10*loss_b\n",
    "loss=1*loss_g+1*loss_phi# +0.001*(reg1+reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_Adam1 = tf.train.AdamOptimizer(1e-3)\n",
    "train_op_Adam1 = optimizer_Adam1.minimize(loss_phi)\n",
    "\n",
    "optimizer_Adam2 = tf.train.AdamOptimizer(1e-3)\n",
    "train_op_Adam2 = optimizer_Adam2.minimize(loss_g)\n",
    "\n",
    "optimizer_Adam3 = tf.train.AdamOptimizer(1e-3)\n",
    "train_op_Adam3 = optimizer_Adam3.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g_record = []\n",
    "loss_phi_record = []\n",
    "loss_phi1_record = []\n",
    "loss_phi2_record = []\n",
    "loss_b_record=[]\n",
    "saver = tf.train.Saver(max_to_keep=1000)\n",
    "savedir='xiaoli'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "min_loss = 1e16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1.26e+02  2.56e+01  1.01e+02  4.40e+01  3.42e+00  5.33e+00  6.92e-04  -8.83e-01   1.12e-02  -8.83e-01 \n",
      "  1000  7.80e-02  6.57e-02  1.23e-02  5.90e-03  6.39e-03  3.47e-06  -1.00e+00  1.00e+00   3.54e-04  1.83e-03 \n",
      "  2000  2.96e-02  2.00e-02  9.62e-03  5.29e-03  4.33e-03  7.57e-07  -1.00e+00  1.00e+00   2.48e-04  8.13e-04 \n",
      "  3000  1.83e-02  8.96e-03  9.33e-03  4.94e-03  4.39e-03  5.97e-08  -1.00e+00  1.00e+00   2.34e-04  6.37e-05 \n",
      "  4000  1.39e-02  4.63e-03  9.24e-03  4.91e-03  4.32e-03  7.86e-08  -1.00e+00  1.00e+00   2.41e-04  -1.12e-04 \n",
      "  5000  1.17e-02  2.57e-03  9.18e-03  4.89e-03  4.29e-03  1.21e-07  -1.00e+00  1.00e+00   2.45e-04  -2.25e-04 \n",
      "  6000  1.06e-02  1.48e-03  9.11e-03  4.84e-03  4.27e-03  1.39e-07  -1.00e+00  1.00e+00   2.40e-04  -2.72e-04 \n",
      "  7000  9.91e-03  8.73e-04  9.03e-03  4.78e-03  4.26e-03  1.26e-07  -1.00e+00  1.00e+00   2.25e-04  -2.65e-04 \n",
      "  8000  9.46e-03  5.20e-04  8.94e-03  4.67e-03  4.27e-03  9.40e-08  -1.00e+00  1.00e+00   2.02e-04  -2.23e-04 \n",
      "  9000  9.16e-03  3.12e-04  8.85e-03  4.55e-03  4.30e-03  6.25e-08  -1.00e+00  1.00e+00   1.90e-04  -1.54e-04 \n",
      "  10000  8.94e-03  1.88e-04  8.76e-03  4.40e-03  4.35e-03  1.01e-07  -1.00e+00  1.00e+00   1.81e-04  -6.94e-05 \n",
      "  11000  8.90e-03  1.14e-04  8.79e-03  4.27e-03  4.45e-03  6.64e-06  -1.00e+00  9.97e-01   1.38e-04  -9.96e-06 \n",
      "  12000  8.72e-03  6.89e-05  8.65e-03  4.20e-03  4.45e-03  7.63e-08  -1.00e+00  1.00e+00   1.70e-04  -2.90e-05 \n",
      "  13000  8.67e-03  4.17e-05  8.63e-03  4.15e-03  4.46e-03  2.29e-06  -1.00e+00  1.00e+00   4.48e-04  -1.44e-03 \n",
      "  14000  8.94e-03  2.53e-05  8.91e-03  4.17e-03  4.50e-03  2.49e-05  -9.99e-01  9.95e-01   6.60e-05  5.00e-04 \n",
      "  15000  8.58e-03  1.53e-05  8.56e-03  4.02e-03  4.49e-03  5.43e-06  -1.00e+00  1.00e+00   4.38e-04  -1.47e-03 \n",
      "  16000  8.20e-03  9.30e-06  8.19e-03  3.68e-03  4.50e-03  1.92e-07  -1.00e+00  1.00e+00   2.03e-04  -1.63e-04 \n",
      "  17000  7.60e-03  5.64e-06  7.60e-03  3.05e-03  4.52e-03  2.70e-06  -1.00e+00  9.98e-01   2.11e-04  -1.54e-05 \n",
      "  18000  7.17e-03  3.42e-06  7.17e-03  2.66e-03  4.51e-03  1.11e-07  -1.00e+00  1.00e+00   1.89e-04  -2.66e-05 \n",
      "  19000  7.00e-03  2.08e-06  7.00e-03  2.51e-03  4.49e-03  2.94e-08  -1.00e+00  1.00e+00   1.52e-04  -3.80e-06 \n",
      "  20000  6.95e-03  1.26e-06  6.95e-03  2.47e-03  4.48e-03  2.21e-08  -1.00e+00  1.00e+00   1.34e-04  -7.00e-06 \n",
      "  21000  7.20e-03  7.64e-07  7.20e-03  2.51e-03  4.49e-03  2.03e-05  -1.00e+00  1.00e+00   1.08e-03  -4.37e-03 \n",
      "  22000  6.91e-03  4.63e-07  6.91e-03  2.44e-03  4.47e-03  3.39e-08  -1.00e+00  1.00e+00   7.91e-05  1.60e-04 \n",
      "  23000  6.90e-03  2.81e-07  6.90e-03  2.42e-03  4.48e-03  9.92e-08  -1.00e+00  1.00e+00   4.34e-05  3.09e-04 \n",
      "  24000  6.89e-03  1.71e-07  6.89e-03  2.41e-03  4.47e-03  2.82e-07  -1.00e+00  1.00e+00   1.06e-04  -2.59e-06 \n",
      "  25000  6.88e-03  1.04e-07  6.88e-03  2.40e-03  4.48e-03  5.20e-08  -1.00e+00  1.00e+00   5.59e-05  2.16e-04 \n",
      "  26000  6.87e-03  6.31e-08  6.87e-03  2.40e-03  4.47e-03  1.36e-08  -1.00e+00  1.00e+00   1.09e-04  -2.44e-06 \n",
      "  27000  6.87e-03  3.84e-08  6.87e-03  2.39e-03  4.47e-03  1.30e-08  -1.00e+00  1.00e+00   1.06e-04  -2.80e-06 \n",
      "  28000  6.86e-03  2.34e-08  6.86e-03  2.39e-03  4.47e-03  3.09e-08  -1.00e+00  1.00e+00   9.84e-05  1.69e-06 \n",
      "  29000  6.92e-03  1.43e-08  6.92e-03  2.36e-03  4.52e-03  4.40e-06  -1.00e+00  1.00e+00   -4.17e-04  2.06e-03 \n",
      "  30000  7.48e-03  8.79e-09  7.48e-03  2.56e-03  4.46e-03  4.62e-05  -1.00e+00  1.01e+00   4.98e-05  2.19e-04 \n",
      "  31000  6.85e-03  5.44e-09  6.85e-03  2.38e-03  4.47e-03  1.04e-08  -1.00e+00  1.00e+00   9.60e-05  -6.25e-07 \n",
      "  32000  7.33e-03  3.41e-09  7.33e-03  2.48e-03  4.49e-03  3.53e-05  -1.00e+00  9.99e-01   1.66e-03  -5.68e-03 \n",
      "  33000  7.03e-03  2.17e-09  7.03e-03  2.32e-03  4.59e-03  1.29e-05  -1.00e+00  1.00e+00   -7.60e-04  3.42e-03 \n",
      "  34000  6.85e-03  1.41e-09  6.85e-03  2.38e-03  4.47e-03  2.57e-08  -1.00e+00  1.00e+00   8.70e-05  -8.93e-06 \n",
      "  35000  7.11e-03  9.45e-10  7.11e-03  2.45e-03  4.46e-03  1.97e-05  -1.00e+00  1.00e+00   3.11e-05  4.21e-05 \n",
      "  36000  6.93e-03  6.56e-10  6.93e-03  2.41e-03  4.46e-03  5.68e-06  -1.00e+00  1.00e+00   2.57e-05  3.49e-04 \n",
      "  37000  6.85e-03  4.73e-10  6.85e-03  2.38e-03  4.47e-03  8.69e-09  -1.00e+00  1.00e+00   8.56e-05  -3.43e-06 \n",
      "  38000  6.84e-03  3.54e-10  6.84e-03  2.38e-03  4.47e-03  8.12e-09  -1.00e+00  1.00e+00   6.87e-05  4.93e-05 \n",
      "  39000  6.92e-03  2.75e-10  6.92e-03  2.40e-03  4.47e-03  5.40e-06  -1.00e+00  1.00e+00   5.12e-05  1.70e-05 \n",
      "  40000  6.85e-03  2.21e-10  6.85e-03  2.38e-03  4.47e-03  2.51e-07  -1.00e+00  1.00e+00   8.81e-05  1.92e-05 \n",
      "  41000  6.84e-03  1.83e-10  6.84e-03  2.37e-03  4.47e-03  1.24e-08  -1.00e+00  1.00e+00   8.30e-05  -1.16e-05 \n",
      "  42000  6.84e-03  1.55e-10  6.84e-03  2.37e-03  4.47e-03  2.54e-08  -1.00e+00  1.00e+00   4.78e-05  1.50e-04 \n",
      "  43000  6.84e-03  1.34e-10  6.84e-03  2.37e-03  4.47e-03  5.89e-09  -1.00e+00  1.00e+00   7.31e-05  -1.42e-06 \n",
      "  44000  7.01e-03  1.18e-10  7.01e-03  2.41e-03  4.47e-03  1.30e-05  -9.99e-01  9.97e-01   1.09e-04  -9.37e-06 \n",
      "  45000  6.84e-03  1.05e-10  6.84e-03  2.37e-03  4.47e-03  1.07e-07  -1.00e+00  1.00e+00   9.41e-05  -7.08e-06 \n",
      "  46000  6.83e-03  9.51e-11  6.83e-03  2.36e-03  4.47e-03  1.24e-07  -1.00e+00  1.00e+00   -2.76e-05  3.50e-04 \n",
      "  47000  6.83e-03  8.66e-11  6.83e-03  2.36e-03  4.47e-03  3.54e-09  -1.00e+00  1.00e+00   5.57e-05  6.45e-06 \n",
      "  48000  7.00e-03  7.94e-11  7.00e-03  2.39e-03  4.48e-03  1.35e-05  -9.99e-01  9.97e-01   1.53e-04  9.39e-05 \n",
      "  49000  6.89e-03  7.34e-11  6.89e-03  2.39e-03  4.44e-03  4.97e-06  -1.00e+00  1.00e+00   5.86e-04  -2.15e-03 \n",
      "  50000  6.82e-03  6.82e-11  6.82e-03  2.35e-03  4.47e-03  6.76e-08  -1.00e+00  1.00e+00   5.71e-05  -3.92e-05 \n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    g_pred=neural_net_g(vect_tf, weights_g1, biases_g1,weights_g2, biases_g2)\n",
    "    phi_pred=neural_net_phi(vect_tf,weights_phi1,biases_phi1,weights_phi2,biases_phi2) \n",
    "    for i in range(50001):\n",
    "\n",
    "        sess.run(train_op_Adam3 )\n",
    "#         sess.run(train_op_Adam1 )\n",
    "#         if i%10==0:\n",
    "#             sess.run(train_op_Adam2 )\n",
    "        if i % 1000 == 0:\n",
    "            (loss_result,loss_g_result, loss_phi_result ,  loss_phi1_result , loss_phi2_result ,loss_b_result ) = sess.run([loss,loss_g, loss_phi,loss_phi1,loss_phi2,loss_b])\n",
    "            (phi1L_np,phi1R_np,phi2L_np,phi2R_np)=sess.run([phi1L_nn,phi1R_nn,phi2L_nn,phi2R_nn])\n",
    "            g_t0= sess.run(g_pred)\n",
    "            phi_t0= sess.run(phi_pred)\n",
    "            loss_g_record.append(loss_g_result)\n",
    "            loss_phi_record.append(loss_phi_result)\n",
    "            loss_phi1_record.append(loss_phi1_result)\n",
    "            loss_phi2_record.append(loss_phi2_result)\n",
    "            loss_b_record.append(loss_b_result)\n",
    "            if loss_result<min_loss:\n",
    "                min_loss=loss_result\n",
    "                g_opt= sess.run(g_pred) \n",
    "                phi_opt= sess.run(phi_pred)\n",
    "                i_opt=i\n",
    "           # temp_loss=sess.run(loss, feed_dict = all_dict)\n",
    "            print ('  %d  %8.2e  %8.2e  %8.2e  %8.2e  %8.2e  %8.2e  %8.2e  %8.2e   %8.2e  %8.2e ' % (i, loss_result,loss_g_result,loss_phi_result,loss_phi1_result,loss_phi2_result,loss_b_result,phi1L_np,phi1R_np,phi2L_np,phi2R_np) )\n",
    "\n",
    "        if i % 50000 == 0:\n",
    "            #save_path = saver.save(sess, savedir+'/' + str(i) + '.ckpt')\n",
    "            (weights_g1_np,biases_g1_np,weights_g2_np,biases_g2_np,weights_phi1_np,biases_phi1_np,weights_phi2_np,biases_phi2_np )=sess.run([weights_g1,biases_g1,weights_g2,biases_g2,weights_phi1,biases_phi1, weights_phi2,biases_phi2 ])\n",
    "            sample_list = {\"weights_g1\": weights_g1_np, \"biases_g1\": biases_g1_np,\"weights_g2\": weights_g2_np, \"biases_g2\": biases_g2_np,\"weights_phi1\": weights_phi1_np, \"biases_phi1\": biases_phi1_np,\"weights_phi2\": weights_phi2_np, \"biases_phi2\": biases_phi2_np}\n",
    "            file_name = './result/hyper' + str(i) + '.pkl'\n",
    "            open_file = open(file_name, \"wb\")\n",
    "            pickle.dump(sample_list, open_file)\n",
    "            open_file.close()\n",
    "            np.savetxt('./result/loss_g'+'_T_'+str(t1) + '_iter_'+str(i)+'.txt',np.array(loss_g_record),fmt='%10.5e')\n",
    "            np.savetxt('./result/loss_phi_g'+'_T_'+str(t1) + '_iter_'+str(i)+'.txt',np.array(loss_phi_record),fmt='%10.5e')\n",
    "            np.savetxt('./result/loss_b'+'_T_'+str(t1) + '_iter_'+str(i)+'.txt',np.array(loss_b_record),fmt='%10.5e')\n",
    "\n",
    "\n",
    "         #   np.savetxt('./result/loss_g-mat.txt',np.array(loss_g_record),fmt='%10.5e')\n",
    "        #    np.savetxt('./result/loss_phi-mat.txt',np.array(loss_phi_record),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/loss_b-mat.txt',np.array(loss_b_record),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/g1' + str(i) + '-mat.txt',np.array(g_t0[0]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/g2' + str(i) + '-mat.txt',np.array(g_t0[1]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/phi1_' + str(i) + '-mat.txt',np.array(phi_t0[0]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/phi2_' + str(i) + '-mat.txt',np.array(phi_t0[1]),fmt='%10.5e')\n",
    "            \n",
    "         #   np.savetxt('./result/g1_opt-mat.txt',np.array(g_opt[0]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/g2_opt-mat.txt',np.array(g_opt[1]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/phi1_opt-mat.txt',np.array(phi_opt[0]),fmt='%10.5e')\n",
    "         #   np.savetxt('./result/phi2_opt-mat.txt',np.array(phi_opt[1]),fmt='%10.5e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./result/weights_phi1_0.txt',np.array(weights_phi1_np[0]),fmt='%10.5e')\n",
    "np.savetxt('./result/weights_phi1_1.txt',np.array(weights_phi1_np[1]),fmt='%10.5e') \n",
    "np.savetxt('./result/weights_phi1_2.txt',np.array(weights_phi1_np[2]),fmt='%10.5e') \n",
    "np.savetxt('./result/biases_phi1_0.txt',np.array(biases_phi1_np[0]),fmt='%10.5e')\n",
    "np.savetxt('./result/biases_phi1_1.txt',np.array(biases_phi1_np[1]),fmt='%10.5e') \n",
    "np.savetxt('./result/biases_phi1_2.txt',np.array(biases_phi1_np[2]),fmt='%10.5e') \n",
    "\n",
    "np.savetxt('./result/weights_phi2_0.txt',np.array(weights_phi2_np[0]),fmt='%10.5e')\n",
    "np.savetxt('./result/weights_phi2_1.txt',np.array(weights_phi2_np[1]),fmt='%10.5e') \n",
    "np.savetxt('./result/weights_phi2_2.txt',np.array(weights_phi2_np[2]),fmt='%10.5e') \n",
    "np.savetxt('./result/biases_phi2_0.txt',np.array(biases_phi2_np[0]),fmt='%10.5e')\n",
    "np.savetxt('./result/biases_phi2_1.txt',np.array(biases_phi2_np[1]),fmt='%10.5e') \n",
    "np.savetxt('./result/biases_phi2_2.txt',np.array(biases_phi2_np[2]),fmt='%10.5e') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=  plt.figure()\n",
    "plt.plot(phi_opt[0],phi_opt[1],'r', label='$\\phi_{NN}$' ) \n",
    "plt.xlabel('$\\phi_1$')\n",
    "plt.ylabel('$\\phi_2$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#fig.savefig('2d_phi_T'+str(t1)+'_alpha'+str(alpha)+'_end_100total_dw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=  plt.figure()\n",
    "plt.plot(phi_t0[0],phi_t0[1],'r', label='$\\phi_{NN}$' ) \n",
    "plt.xlabel('$\\phi_1$')\n",
    "plt.ylabel('$\\phi_2$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#fig.savefig('2d_phi_T'+str(t1)+'_alpha'+str(alpha)+'_end_100total_dw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=  plt.figure()\n",
    "plt.plot(vect,phi_t0[0],'r', label='$\\phi_{1NN}$' ) \n",
    "plt.plot(vect,phi_t0[1],'g', label='$\\phi_{2NN}$' ) \n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\phi$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#fig.savefig('2d_phi_T'+str(t1)+'_alpha'+str(alpha)+'_end_100total_dw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=  plt.figure()\n",
    "plt.plot(vect,phi_opt[0],'r', label='$\\phi_{NN}$' )\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\phi_0$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#fig.savefig('2d_phi_T'+str(t1)+'_alpha'+str(alpha)+'_opt_100total_dw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=  plt.figure()\n",
    "plt.plot(vect,phi_opt[1],'r', label='$\\phi_{NN}$' )\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$\\phi_1$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#fig.savefig('2d_phi_T'+str(t1)+'_alpha'+str(alpha)+'_opt_100total_dw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vect,g_t0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vect,g_t0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "xl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
